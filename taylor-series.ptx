<section xml:id="taylor-series">
  <title>Taylor Series</title>
  <definition>
    <statement>
      <p>
        A function is <term>analytic</term>
        if it can be expressed as a <term>Taylor series</term>.
        <me>
          f(x) = \sum_{n=0}^\infty c_n (x-\alpha)^n
        </me>
      </p>
      <p>
        A Taylor series is centered at a point <m>\alpha</m>;
        if <m>\alpha = 0</m> we call it a
        <term>McLaurin series</term>.
        A series defines a function on some domain
        <m>(\alpha-R,\alpha+R)</m> for some number <m>R \geq 0</m>,
        which is called a <term>radius of convergence</term>.
        If <m>R=\infty</m>, the series is defined on all real numbers.
        If <m>R=0</m>, the series is only defined at
        <m>x=\alpha</m> and is basically useless.
      </p>
    </statement>
  </definition>
  <p>
    We use the ratio or root tests to calculate the radius of convergence of a series.
    After some manipulation of those tests,
    (if the coefficients are non-zer)
    the radius of convergence is given by the formula
    <me>
      R = \lim_{n \rightarrow \infty} \left| \frac{c_n}{c_{n+1}} \right| = \lim_{n \rightarrow \infty} \frac{1}{\sqrt[n]{|c_n|}}
    </me>.
  </p>
  <p>
    Inside the radius of convergence,
    the behaviour of a Taylor series is very reasonable.
    We can add and subtract terms when the indices match.
    We can multiply series like polynomials,
    though the calculation gets arduous.
    We can even divide using long division
    (though it is an infinite process).
    With multiplication and division
    (and with many other uses of series),
    we often only calculate the first few terms of the series.
  </p>
  <p>
    There are two important manupulation techniques for series.
    The first is adjustment on indices.
    <me>
      \sum_{n=k}^\infty c_n x^n = \sum_{n=k+1}^\infty c_{n-1} x^{n-1} = \sum_{n=k-1}^\infty c_{n+1} x^{n+1}
    </me>
  </p>
  <p>
    The second is removal of initial terms.
    <me>
      \sum_{n=0}^\infty c_n x_n = c_0 + c_1 x + c_2 x^2 + \sum_{n=3}^\infty c_n x_n
    </me>
  </p>
  <p>
    Inside the radius of convergence,
    the calculus of Taylor series is well behaved.
    We can integrate and differentiate term-wise.
    <md>
      <mrow>f(x) \amp  = \sum_{n=0}^\infty c_n x^n</mrow>
      <mrow>f^\prime(x) \amp  = \sum_{n=1}^\infty c_n nx^{n-1}</mrow>
      <mrow>\int f(x) dx \amp  = \sum_{n=0}^\infty \frac{c_n x^{n+1}}{n+1} + c</mrow>
    </md>
  </p>
  <p>
    In particular,
    we know that integrals and derivatives are always defined.
    This shows that analytic functions are necessarily
    <m>C^\infty</m> on the domain given by the radius of convergence. (This is, in fact,
    an equivalence:
    any <m>C^\infty</m> function has a Taylor series with some radius <m>R</m>).
  </p>
  <p>
    Evaluating the derivatives of a series at the centre point <m>\alpha</m> gives a list of derivatives.
    <md>
      <mrow>f(\alpha) \amp  = c_0</mrow>
      <mrow>f^{\prime} (\alpha) \amp  = c_1</mrow>
      <mrow>f^{\prime \prime} (\alpha) \amp  = 2c_2</mrow>
      <mrow>f^{(3)} (\alpha) \amp  = 2\cdot 3c_4</mrow>
      <mrow>f^{(4)} (\alpha) \amp  = 4!c_4</mrow>
      <mrow>f^{(n)} (\alpha) \amp  = n!c_n</mrow>
      <mrow>c_n \amp  = \frac{f^{(n)} (\alpha)}{n!}</mrow>
    </md>
  </p>
  <p>
    This is a way to calculate coefficients,
    if we know the derivatives of a function.
    Remember that the coefficients totally describe the taylor series,
    so the derivatives at the centre point give all the information.
  </p>
</section>