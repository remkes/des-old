<section xml:id="bessel-functions">
  <title>Bessel Functions</title>
  <subsection xml:id="gamma-function">
    <title>The <m>\Gamma</m> Function</title>
    <p>
      Before we get to a very interesting example of the method of Frobenious,
      we need to define the <m>\Gamma</m> (gamma)function.
      This is a ubiquitous and useful function which generalizes the factorial.
    </p>
    <definition>
      <statement>
        <p>
          The <m>\Gamma</m> function is defined by this integral
          <me>
            \Gamma(t) = \int_0^\infty x^{t-1}e^{-x} dx
          </me>.
        </p>
        <p>
          The <m>\Gamma</m> function is defined on all <m>\RR</m> except 0 and negative integers.
          It is continuous and differentiable on <m>(0, \infty)</m>.
        </p>
      </statement>
    </definition>
    <p>
      There are several important properties of <m>\Gamma(t)</m>: First,
      (as mentioned)
      it generalizes the factorial.
      <md>
        <mrow>\Gamma(a+1) \amp  = a \Gamma(a)</mrow>
        <mrow>\Gamma(1) \amp  = 1</mrow>
        <mrow>\Gamma(n) \amp  = (n-1)! \text{ for }  n \in \NN</mrow>
      </md>
    </p>
    <p>
      Asymptotically,
      the factorial nature of the <m>\Gamma</m> functions means it grows faster than <m>e^t</m>.
    </p>
    <p>
      If the positive integer values of the <m>\Gamma</m> function generalize the factorial,
      what can be expect for other values?
      The results are surprising.
      Look at the value of <m>\Gamma(\frac{1}{2})</m>
      (in this calculation,
      we use a well-known result for the integral <m>e^{-u^2}</m>).
      <md>
        <mrow>\Gamma \left( \frac{1}{2} \right) \amp  = \int_0^\infty x^{-\frac{1}{2}} e^{-x} dx</mrow>
        <mrow>x \amp  = u^2</mrow>
        <mrow>dx \amp  = 2u du</mrow>
        <mrow>x^{-\frac{1}{2}} \amp  = \frac{1}{u}</mrow>
        <mrow>\amp  = 2 \int_0^\infty e^{-u^2} u \frac{1}{u} du</mrow>
        <mrow>\amp  = 2 \int_0^\infty e^{-u^2}</mrow>
        <mrow>\amp  = 2 \frac{\sqrt{\pi}}{2} = \sqrt{\pi}</mrow>
      </md>
    </p>
    <p>
      Then, from the factorial-like nature of <m>\Gamma</m>,
      all other half-integer values are multiples of <m>\sqrt{\pi}</m>.
      <me>
        \Gamma\left( \frac{2n+1}{2} \right) = \frac{ (3)(5)(7) \ldots (2n-1) \sqrt{\pi}}{2^n}
      </me>
    </p>
  </subsection>
  <subsection xml:id="bessel-equation">
    <title>Bessel's Equation</title>
    <p>
      The method of Frobenius is used to solve a historically interesting equation: Bessel's Equation.
      This equation shows up in harmonic problems with certain cirucular boundary conditions,
      such as the vibrations on a drum.
      It is also useful for springs with fatigue
      (where the spring constant gets weaker over time),
      the quantum model of the hydrogen atom,
      and various electical/gravitational potentials
      (particular those which are circularly or spherically symmetric).
      Its solutions are another piece of the mathematics of special functions.
    </p>
    <p>
      Let <m>\nu \in \RR</m>.
      Bessel's equation of order <m>\nu</m> is the equation
      <me>
        t^2 y^{\prime \prime} + t y^\prime + (t^2 - \nu^2) y = 0
      </me>.
    </p>
    <p>
      Written in standard form,
      <m>0</m> is a regular singular point of Bessel's equation.
      <md>
        <mrow>P(t) \amp  = \frac{1}{t} \implies p_{-1} = 1</mrow>
        <mrow>Q(t) \amp  = 1-\frac{\nu^2}{t^2} \implies q_{-2} = -\nu^2</mrow>
      </md>
    </p>
    <p>
      We calculate the indicial equation.
      <md>
        <mrow>r(r-1) + r - \nu^2 \amp  = 0</mrow>
        <mrow>r^2 -r + r - \nu^2 \amp  = 0</mrow>
        <mrow>r^2 \amp  = \nu^2</mrow>
        <mrow>r \amp  = \pm \nu</mrow>
      </md>
    </p>
    <p>
      We start with <m>r = \nu</m> first and assume that
      <m>\nu \geq 0</m> without loss of generality.
      We calculate the derivatives of <m>y</m>.
      <md>
        <mrow>y \amp  = \sum_{n=0}^\infty c_n t^{n+\nu}</mrow>
        <mrow>y^\prime \amp  = \sum_{n=0}^\infty c_n(n+\nu) t^{n+\nu- 1}</mrow>
        <mrow>y^{\prime\prime} \amp  = \sum_{n=0}^\infty c_n(n+\nu)(n+\nu-1) t^{n+\nu- 2}</mrow>
      </md>
    </p>
    <p>
      Then we proceed with a lengthly calculation.
      <md>
        <mrow>t^2 y^{\prime \prime} + t y^\prime + (t^2 - \nu^2) y \amp  = 0</mrow>
        <mrow>t^2 \sum_{n=0}^\infty c_n(n+\nu)(n+\nu-1) + t \sum_{n=0}^\infty c_n(n+\nu) t^{n+\nu- 1} + t^2 \sum_{n=0}^\infty c_n t^{n+\nu} - \nu^2 \sum_{n=0}^\infty c_n t^{n+\nu} \amp  = 0</mrow>
        <mrow>\sum_{n=0}^\infty c_n(n+\nu)(n+\nu-1) t^{n+\nu} + \sum_{n=0}^\infty c_n(n+\nu) t^{n+\nu} + \sum_{n=0}^\infty c_n t^{n+\nu+2} - \sum_{n=0}^\infty \nu^2 c_n t^{n+\nu} \amp  = 0</mrow>
        <mrow>\sum_{n=0}^\infty c_n(n+\nu)(n+\nu-1) t^{n+\nu} + \sum_{n=0}^\infty c_n(n+\nu) t^{n+\nu} + \sum_{n=2}^\infty c_{n-2} t^{n+\nu} - \sum_{n=0}^\infty \nu^2 c_n t^{n+\nu} \amp  = 0</mrow>
        <mrow>\nu(\nu-1) c_0 t^\nu + (\nu+1) \nu c_1 t^{\nu+1} + \nu c_0 t^\nu + (\nu+1)c_1t^{\nu+1} - \nu^2 c_0 t^\nu - \nu^2 c_1 t^{\nu+1} \amp</mrow>
        <mrow>+ \sum_{n=2}^\infty c_n(n+\nu)(n+\nu-1) t^{n+\nu} + \sum_{n=2}^\infty c_n(n+\nu) t^{n+\nu} + \sum_{n=2}^\infty c_{n-2} t^{n+\nu} - \sum_{n=2}^\infty \nu^2 c_n t^{n+\nu} \amp  = 0</mrow>
        <mrow>\nu(\nu-1) c_0 t^\nu + (\nu+1) \nu c_1 t^{\nu+1} + \nu c_0 t^\nu + (\nu+1)c_1t^{\nu+1} - \nu^2 c_0 t^\nu - \nu^2 c_1 t^{\nu+1} \amp</mrow>
        <mrow>+ \sum_{n=2}^\infty \left[ c_n(n+\nu)(n+\nu-1) + c_n(n+\nu) + c_{n-2} - \nu^2 c_n \right] t^{n+\nu} \amp  = 0</mrow>
      </md>
    </p>
    <p>
      Look at the coefficient of <m>t^{\nu}</m>.
      <md>
        <mrow>\left( (\nu^2 - \nu) c_0 +\nu c_0 - \nu^2 c_0 \right) \amp  = 0</mrow>
        <mrow>\left( \nu^2 - \nu + \nu - \nu^2 \right) c_0 \amp  = 0</mrow>
        <mrow>0 c_0 \amp  = 0</mrow>
      </md>
    </p>
    <p>
      Therefore, <m>c_0</m> is free.
      Look at the coefficient of <m>t^{\nu+1}</m>.
      <md>
        <mrow>\left( \nu(\nu+1)c_1 + (\nu+1) c_1 - \nu^2 c_1 \right) \amp  = 0</mrow>
        <mrow>\left( \nu^2 + \nu + \nu + 1 - \nu^2 \right) c_1 \amp  = 0</mrow>
        <mrow>\left( 2 \nu + 1 \right) c_1 \amp  =0</mrow>
      </md>
    </p>
    <p>
      So <m>c_1 = 0</m> unless <m>\nu = \frac{-1}{2}</m>.
      However, we assumed that we were dealing with <m>\nu</m> positive,
      so we conclude that <m>c_1 = 0</m>.
      (We'll pay some special attention to
      <m>\nu = \frac{-1}{2}</m> when we look at negative <m>\nu</m>,
      and to half-integer values of <m>\nu</m> in general.)
    </p>
    <p>
      Then we have the general recurrence relation, for <m>n \geq 2</m>.
      <md>
        <mrow>((n+\nu)(n+\nu-1) + n + \nu - \nu^2) c_n + c_{n-2} \amp  = 0</mrow>
        <mrow>(n^2 + n\nu + n\nu + \nu^2 - n - \nu + n + \nu - \nu^2 ) c_n \amp = -c_{n-2}</mrow>
        <mrow>(n^2 + 2n\nu) c_n \amp  = -c_{n-2}</mrow>
        <mrow>c_n \amp  = \frac{-c_{n-2}}{n(n+2\nu)}</mrow>
        <mrow>c_{n+2} \amp  = \frac{-c_n}{(n+2)(n+2+2\nu)}</mrow>
      </md>
    </p>
    <p>
      These are the equations that calculate coefficients, so we start calculating.
      <md>
        <mrow>c_0 \amp  = c_0</mrow>
        <mrow>(2\nu+1) c_1 \amp  = 0 \implies c_1 = 0 \implies c_{2n+1} = 0 \ \forall n \in \NN</mrow>
        <mrow>c_2 \amp  = \frac{-c_0}{2(2+2\nu)}</mrow>
        <mrow>c_4 \amp  = \frac{c_0}{(2)(4)(2+2\nu)(4+2\nu)}</mrow>
        <mrow>c_6 \amp  = \frac{-c_0}{(2)(4)(6)(2+2\nu)(4+2\nu)(6+2\nu)}</mrow>
        <mrow>c_8 \amp  = \frac{c_0}{(2)(4)(6)(8)(2+2\nu)(4+2\nu)(6+2\nu) (8+2\nu)}</mrow>
        <mrow>c_{2n} \amp  = \frac{(-1)^n c_0}{2^{2n} n! (1+\nu)(2+\nu) \ldots (n+\nu)}</mrow>
      </md>
    </p>
    <p>
      The constant <m>c_0</m> is still undetermined.
      By convention, the choice for <m>c_0</m> is this strange value
      <me>
        c_0 = \frac{1}{2^\nu \Gamma(1+\nu)}
      </me>.
    </p>
    <p>
      The properties of the <m>\Gamma</m> function allow us to simplify the denominator of the <m>c_n</m>.
      <me>
        c_{2n} = \frac{(-1)^n}{2^\nu \Gamma(1+\nu)} \frac{1}{2^{2n}n! (\nu+1) \ldots (\nu+n)} = \frac{(-1)^n}{2^{2n+v} n! \Gamma(1+n+\nu)}
      </me>
    </p>
    <p>
      With this simplification,
      we can write the final solution for positive <m>\nu</m>.
    </p>
    <definition>
      <statement>
        <p>
          The solution constructed above is written <m>J_\nu</m> and called the Bessel function of the first kind of order <m>\nu</m>.
          <me>
            J_{\nu} = \sum_{n=0}^\infty \frac{(-1)^n}{n! \Gamma(1+n+\nu)} \left( \frac{t}{2} \right)^{2n+\nu}
          </me>
        </p>
        <p>
          It converges on <m>(0, \infty)</m>.
          It may not be defined at 0 or negative numbers.
          In general, we are only interested in the Bessel function on the domain <m>(0, \infty)</m>.
          The Bessel functions of the first kind for
          <m>\nu \in \ZZ</m> are show in <xref ref="figure-bessel-first-kind">Figure</xref>.
        </p>
      </statement>
    </definition>
    <figure xml:id="figure-bessel-first-kind">
      <caption>Integer-Order Bessel Functions of the First Kind</caption>
      <image width="1100%" source="images/figure21.png" />
    </figure>
    <figure xml:id="figure-bessel-second-kind">
      <caption>Integer-Order Bessel Functions of the Second Kind</caption>
      <image width="1100%" source="images/figure22.png" />
    </figure>
    <p>
      We could redo the same work for negative <m>\nu</m>,
      but it is very similar (for <m>n = \frac{-1}{2}</m>,
      we would get a term <m>(2\nu - 1) c_1</m>,
      so we would still conclude that <m>c_1 = 0</m>,
      hence all odd coefficients are <m>0</m>).
      In this way,
      we find the rest of the Bessel functions of the first kind.
      <me>
        J_{-\nu} = \sum_{n=0}^\infty \frac{(-1)^n}{n! \Gamma(1+n-\nu)} \left( \frac{t}{2} \right)^{2n-\nu}
      </me>
    </p>
    <p>
      One caution should be noted.
      If <m>n \in \NN</m>, this <m>J_{-n}</m> gives an undefined denominator,
      hence doesn't define a series.
      In these cases,
      the method of Frobenius gives <m>J_{-n} = (-1)^n J_{n}</m>.
      This is not necessarily surprising:
      in the method of Frobenius,
      is the roots of the indicial equation differ by an integer,
      we may not have linearly independent solution.
      If <m>\nu \notin \ZZ</m>,
      then we have two linearly independent solutions,
      as we would expect with the method of Frobenius.
    </p>
    <definition>
      <statement>
        <p>
          Let <m>n \notin \ZZ</m>.
          The <term>Bessel function of the second kind</term>
          of order <m>\nu</m> are written <m>Y_{\nu}</m> and defined by this expression
          <me>
            Y_{\nu} = \frac{\cos (\nu \pi) J_{\nu}(t) - J_{-\nu}(t)}{\sin \nu \pi}
          </me>.
        </p>
        <p>
          This definition is a linear combination of Bessel functions of the first kind.
          For <m>\nu \in \ZZ</m>,
          this linear combination have been just a multiple of the one solution we know.
          To get around this, for <m>\nu \in \ZZ</m>,
          we define the Bessel function of the second kind as a limit.
          <me>
            Y_{\nu}(t) = \lim_{\alpha \rightarrow \nu} Y_{\alpha}(t)
          </me>
        </p>
        <p>
          L'Hopital's rule shows that this limit exists.
          The Bessel functions of the second kind are shown in <xref ref="figure-bessel-second-kind">Figure</xref>.
        </p>
      </statement>
    </definition>
    <p>
      To summarize,
      for any <m>\nu \geq 0</m> we have <m>J_{\nu}</m> and <m>Y_{\nu}</m>,
      two linearly independent solutions to the differential equation.
      The general solution is
      <me>
        y = A J_{\nu} + B Y_{\nu}
      </me>.
    </p>
  </subsection>
  <subsection xml:id="aging-spring">
    <title>The Aging Spring</title>
    <p>
      Consider the spring equation from before.
      <me>
        my^{\prime \prime} + by^\prime + ky = 0
      </me>
    </p>
    <p>
      Now, instead of all constants,
      lets assume this is an aging spring.
      That is, at time passes, the spring constant decreases.
      One model is exponential decay,
      so let <m>k(t) = ke^{-\alpha t}</m> for <m>\alpha > 0</m>.
      Let's see what happens without friction.
      <me>
        m y^{\prime \prime} + ke^{-\alpha t} = 0
      </me>
    </p>
    <p>
      Here's a strange change of variables.
      <md>
        <mrow>s \amp  = \frac{2}{\alpha} \sqrt{\frac{k}{m}} e^{\frac{-\alpha t}{2}}</mrow>
        <mrow>\frac{ds}{dt} \amp  = \frac{2}{\alpha} \frac{-\alpha}{2} \sqrt{ \frac{4k}{m\alpha^2}} e^{\frac{-\alpha t}{2}} = - \sqrt{\frac{k}{m}} e^{-\frac{\alpha t}{2}}</mrow>
        <mrow>\frac{d^2s}{dt^2} \amp  = \frac{\alpha}{2} \sqrt{\frac{k}{m}} e^{-\frac{\alpha t}{2}}</mrow>
        <mrow>\frac{dy}{dt} \amp  = \frac{dy}{ds} \frac{ds}{dt}</mrow>
        <mrow>\frac{d^2 y}{dt^2} \amp  = \frac{d}{dt} \left( \frac{dy}{ds} \frac{ds}{dt} \right)</mrow>
        <mrow>\amp  = \frac{d^2 s}{dt^2} \frac{dy}{ds} + \frac{ds}{dt} \frac{d}{dt} \frac{dy}{ds}</mrow>
        <mrow>\amp  = \frac{d^2 s}{dt^2} \frac{dy}{ds} + \frac{ds}{dt} \frac{d^2y}{ds^2} \frac{ds}{dt}</mrow>
        <mrow>\amp  = \frac{d^2 s}{dt^2} \frac{dy}{ds} + \left( \frac{ds}{dt} \right)^2 \frac{d^2 y}{ds^2}</mrow>
        <mrow>\amp  = \frac{\alpha}{2} \sqrt{\frac{k}{m}} e^{-\frac{\alpha t}{2}} \frac{dy}{ds} + \frac{k}{m} e^{-\alpha t} \frac{d^2 y}{ds^2}</mrow>
      </md>
    </p>
    <p>
      All this nonsense allows us to alter the original equation as follows.
      (The change from the third to the fourth line involves dividing by <m>m</m>,
      then dividing by <m>\alpha^2</m>, then multiplying by 4.)
      <md>
        <mrow>m y^{\prime \prime} + ke^{-\alpha t} \amp  = 0</mrow>
        <mrow>m \left(\frac{d^2 s}{dt^2} \frac{dy}{ds} + \left( \frac{ds}{dt} \right)^2 \frac{d^2 y}{ds^2} \right) + ke^{-\alpha t} \amp  = 0</mrow>
        <mrow>\frac{m\alpha}{2} \sqrt{\frac{k}{m}} e^{-\frac{\alpha t}{2}} \frac{dy}{ds} + m \frac{k}{m} e^{-\alpha t} + k e^{-\alpha t} y \amp  = 0</mrow>
        <mrow>\frac{2}{\alpha} \sqrt{\frac{k}{m}} e^{-\frac{\alpha t}{2}} \frac{dy}{ds} + \frac{4}{\alpha^2} \frac{k}{m} e^{-\alpha t} \frac{d^y}{ds^2} + \frac{4k}{m\alpha^2} e^{-\alpha t} y \amp  = 0</mrow>
        <mrow>s^2 \frac{d^2y}{ds^2} + s \frac{dy}{ds} + s^2 y \amp  = 0</mrow>
      </md>
    </p>
    <p>
      This is Bessel's equation with <m>\nu = 0</m>.
      It is solved by Bessel's functions
      (of the first and second kind)
      for <m>\nu = 0</m>.
      <md>
        <mrow>y \amp  = A J_0(s) + B Y_0(s)</mrow>
        <mrow>\amp  = A J_0 \left( \frac{2}{\alpha} \sqrt{\frac{k}{m}} e^{-\frac{\alpha t}{2}} \right) + B Y_0 \left( \frac{2}{\alpha} \sqrt{\frac{k}{m}} e^{-\frac{\alpha t}{2}} \right)</mrow>
      </md>
    </p>
    <p>
      These functions completely describe the behaviour of an aging spring with exponential decay of the spring constant.
    </p>
  </subsection>
  <subsection xml:id="bessel-functions-properties">
    <title>Properties of the Bessel Functions</title>
    <p>
      We have some nice symmetry properties for integer orders.
      Let <m>m \in \ZZ</m>.
      <md>
        <mrow>J_{-m}(t) \amp  = (-1)^m J_m(t)</mrow>
        <mrow>J_m(-t) \amp  = (-1)^m J_m(t)</mrow>
      </md>
    </p>
    <p>
      We mentioned a functional equation for the Legendre polynomials.
      We have one here as well; this one is true for arbitrary <m>\nu</m>.
      <me>
        tJ_{\nu}^\prime(t) = \nu J_{\nu}(t) - t J_{\nu+1}(t)
      </me>
    </p>
    <p>
      There are some interesting properties of Bessel functions with half-integer orders.
      Look closely again at <m>J_{\frac{1}{2}}</m>.
      <md>
        <mrow>J_{\frac{1}{2}}(t) \amp  = \sum_{n=0}^\infty \frac{(-1)^n}{n! \Gamma(\frac{3}{2} + n))} \left( \frac{t}{2} \right)^{2n + \frac{1}{2}}</mrow>
        <mrow>\Gamma \left( \frac{3}{2} + n \right) \amp  = \frac{(2n+1)!}{2^{2n+1} n!} \sqrt{\pi}</mrow>
        <mrow>J_{\frac{1}{2}}(t) \amp  = \sum_{n=0}^\infty \frac{(-1)^n} {\frac{(2n+1)!}{2^{2n+1}n!} \sqrt{\pi}} \left( \frac{t}{2} \right)^{2n + \frac{1}{2}}</mrow>
        <mrow>\amp  = \sqrt{\frac{2}{\pi t}} \sum_{n=0}^\infty \frac{(-1)^n}{(2n+1)!} t^{2n+1}</mrow>
        <mrow>\amp  = \sqrt{\frac{2}{\pi t}} \sin t</mrow>
        <mrow>J_{-\frac{1}{2}} \amp  = \sqrt{\frac{2}{\pi t}} \cos t</mrow>
      </md>
    </p>
    <p>
      These special half-integer function can actually be expressed as elementary functions.
      The decay of the amplitude of these waves is <m>\frac{1}{\sqrt{t}}</m> not <m>e^{-t}</m>;
      this decay is much slower than exponential decay.
      The half-integer Bessel functions are called
      <em>spherical Bessel functions</em>.
      The reason for that name is that they solve the wave equation in spherical coordinates.
      The wave equation in <m>\RR^3</m> is
      <m>\nabla^2 A + k^2 A = 0</m> for <m>\nabla^2</m> the Laplacian.
      Changing to spherical coordinates and restricting to the radial terms gives Bessel's equation with half-integer order.
    </p>
    <p>
      We can think of these half-integer Bessel functions as the standing waves of spherical harmonic systems.
      <m>J_{\frac{1}{2}}</m> is the first harmoinc,
      then we get higher harmonics as we go.
      The typical image of these spherical waves are the decaying amplitude ripples radiating from a stone dropped in a pond.
    </p>
  </subsection>
</section>